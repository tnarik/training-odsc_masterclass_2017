{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.read_csv('data/hourly_wages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.024064</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>13.018727</td>\n",
       "      <td>17.822097</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.139097</td>\n",
       "      <td>0.384360</td>\n",
       "      <td>2.615373</td>\n",
       "      <td>12.379710</td>\n",
       "      <td>11.726573</td>\n",
       "      <td>0.498767</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\n",
       "count     534.000000  534.000000     534.000000      534.000000  534.000000   \n",
       "mean        9.024064    0.179775      13.018727       17.822097   36.833333   \n",
       "std         5.139097    0.384360       2.615373       12.379710   11.726573   \n",
       "min         1.000000    0.000000       2.000000        0.000000   18.000000   \n",
       "25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n",
       "50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n",
       "75%        11.250000    0.000000      15.000000       26.000000   44.000000   \n",
       "max        44.500000    1.000000      18.000000       55.000000   64.000000   \n",
       "\n",
       "           female        marr       south  manufacturing  construction  \n",
       "count  534.000000  534.000000  534.000000     534.000000    534.000000  \n",
       "mean     0.458801    0.655431    0.292135       0.185393      0.044944  \n",
       "std      0.498767    0.475673    0.455170       0.388981      0.207375  \n",
       "min      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n",
       "75%      1.000000    1.000000    1.000000       0.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data_df.wage_per_hour.as_matrix()\n",
    "predictors = data_df.drop(['wage_per_hour'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 100)           1000        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           10100       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             101         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "my_model.add(Dense(100, activation='relu'))\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "534/534 [==============================] - 0s - loss: 43.5665      \n",
      "Epoch 2/10\n",
      "534/534 [==============================] - 0s - loss: 25.2800     \n",
      "Epoch 3/10\n",
      "534/534 [==============================] - 0s - loss: 22.8729     \n",
      "Epoch 4/10\n",
      "534/534 [==============================] - 0s - loss: 21.6837     \n",
      "Epoch 5/10\n",
      "534/534 [==============================] - 0s - loss: 21.2656     \n",
      "Epoch 6/10\n",
      "534/534 [==============================] - 0s - loss: 21.2011     \n",
      "Epoch 7/10\n",
      "534/534 [==============================] - 0s - loss: 20.7983     \n",
      "Epoch 8/10\n",
      "534/534 [==============================] - 0s - loss: 20.5152     \n",
      "Epoch 9/10\n",
      "534/534 [==============================] - 0s - loss: 20.8590     \n",
      "Epoch 10/10\n",
      "534/534 [==============================] - 0s - loss: 20.4534     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112183320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 161 samples\n",
      "Epoch 1/10\n",
      "373/373 [==============================] - 0s - loss: 60.3477 - val_loss: 31.9766\n",
      "Epoch 2/10\n",
      "373/373 [==============================] - 0s - loss: 28.5516 - val_loss: 28.5031\n",
      "Epoch 3/10\n",
      "373/373 [==============================] - 0s - loss: 22.2078 - val_loss: 29.9883\n",
      "Epoch 4/10\n",
      "373/373 [==============================] - 0s - loss: 20.6673 - val_loss: 26.2656\n",
      "Epoch 5/10\n",
      "373/373 [==============================] - 0s - loss: 20.5883 - val_loss: 26.3882\n",
      "Epoch 6/10\n",
      "373/373 [==============================] - 0s - loss: 20.0573 - val_loss: 25.9773\n",
      "Epoch 7/10\n",
      "373/373 [==============================] - 0s - loss: 20.1561 - val_loss: 25.3687\n",
      "Epoch 8/10\n",
      "373/373 [==============================] - 0s - loss: 19.8547 - val_loss: 25.8602\n",
      "Epoch 9/10\n",
      "373/373 [==============================] - 0s - loss: 19.5880 - val_loss: 25.4065\n",
      "Epoch 10/10\n",
      "373/373 [==============================] - 0s - loss: 19.6009 - val_loss: 25.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x112fca668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_new_model():\n",
    "    my_model = Sequential()\n",
    "    my_model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "    my_model.add(Dense(100, activation='relu'))\n",
    "    my_model.add(Dense(1))\n",
    "    my_model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    return(my_model)\n",
    "my_model = get_new_model()\n",
    "my_model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 161 samples\n",
      "Epoch 1/20\n",
      "373/373 [==============================] - 0s - loss: 41.2023 - val_loss: 32.1015\n",
      "Epoch 2/20\n",
      "373/373 [==============================] - 0s - loss: 24.8681 - val_loss: 33.5847\n",
      "Epoch 3/20\n",
      "373/373 [==============================] - 0s - loss: 21.0338 - val_loss: 25.6946\n",
      "Epoch 4/20\n",
      "373/373 [==============================] - 0s - loss: 20.1445 - val_loss: 26.6851\n",
      "Epoch 5/20\n",
      "373/373 [==============================] - 0s - loss: 20.2102 - val_loss: 25.2051\n",
      "Epoch 6/20\n",
      "373/373 [==============================] - 0s - loss: 19.9060 - val_loss: 25.3702\n",
      "Epoch 7/20\n",
      "373/373 [==============================] - 0s - loss: 19.7452 - val_loss: 25.1899\n",
      "Epoch 8/20\n",
      "373/373 [==============================] - 0s - loss: 20.0084 - val_loss: 26.5486\n",
      "Epoch 9/20\n",
      "373/373 [==============================] - 0s - loss: 19.5363 - val_loss: 25.7790\n",
      "Epoch 10/20\n",
      "373/373 [==============================] - 0s - loss: 19.2358 - val_loss: 24.7555\n",
      "Epoch 11/20\n",
      "373/373 [==============================] - 0s - loss: 19.2690 - val_loss: 25.1972\n",
      "Epoch 12/20\n",
      "373/373 [==============================] - 0s - loss: 19.0693 - val_loss: 25.3915\n",
      "Epoch 13/20\n",
      "373/373 [==============================] - 0s - loss: 18.9899 - val_loss: 24.4226\n",
      "Epoch 14/20\n",
      "373/373 [==============================] - 0s - loss: 18.8184 - val_loss: 26.1210\n",
      "Epoch 15/20\n",
      "373/373 [==============================] - 0s - loss: 19.7408 - val_loss: 24.6156\n",
      "Epoch 16/20\n",
      "373/373 [==============================] - 0s - loss: 19.3905 - val_loss: 24.5138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113520f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "my_model = get_new_model()\n",
    "my_model.fit(predictors, target, validation_split=0.3, nb_epoch=20, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1           False   \n",
       "1         1       1  38.0      1      0  71.2833     0           False   \n",
       "2         1       3  26.0      0      0   7.9250     0           False   \n",
       "3         1       1  35.0      1      0  53.1000     0           False   \n",
       "4         0       3  35.0      0      0   8.0500     1           False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv('data/titanic_all_numeric.csv')\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/20\n",
      "623/623 [==============================] - 0s - loss: 0.9786 - acc: 0.6308 - val_loss: 0.8166 - val_acc: 0.6418\n",
      "Epoch 2/20\n",
      "623/623 [==============================] - 0s - loss: 0.6796 - acc: 0.6340 - val_loss: 0.5363 - val_acc: 0.7463\n",
      "Epoch 3/20\n",
      "623/623 [==============================] - 0s - loss: 0.6420 - acc: 0.6742 - val_loss: 0.5910 - val_acc: 0.7090\n",
      "Epoch 4/20\n",
      "623/623 [==============================] - 0s - loss: 0.5953 - acc: 0.6966 - val_loss: 0.6522 - val_acc: 0.7052\n",
      "Epoch 5/20\n",
      "623/623 [==============================] - 0s - loss: 0.6186 - acc: 0.6838 - val_loss: 0.6211 - val_acc: 0.7201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113c48d30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "target = to_categorical(titanic_data.survived)\n",
    "predictors = titanic_data.drop(['survived'], axis=1).as_matrix()\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "def get_classification_model(n_cols):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "my_model = get_classification_model(n_cols)\n",
    "my_model.fit(predictors, target, validation_split=0.3, nb_epoch=20, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks (Working with Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Using tf dim ordering\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 27, 27, 8)     40          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 26, 26, 8)     264         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 13, 13, 8)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1352)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 100)           135300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 10)            1010        dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 136,614\n",
      "Trainable params: 136,614\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 8\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (2, 2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape, activation='relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 27, 27, 8)     40          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 26, 26, 8)     264         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 13, 13, 8)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1352)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 100)           135300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 10)            1010        dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 136,614\n",
      "Trainable params: 136,614\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 19s - loss: 0.2117 - acc: 0.9382 - val_loss: 0.0782 - val_acc: 0.9754\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0669 - acc: 0.9789 - val_loss: 0.0546 - val_acc: 0.9825\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0439 - acc: 0.9860 - val_loss: 0.0504 - val_acc: 0.9840\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0463 - val_acc: 0.9858\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 18s - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0521 - val_acc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12386afd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (using Pre-Trained Networks)\n",
    "Loaded model from https://github.com/fchollet/deep-learning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "from vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, None, None, 64 1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, None, None, 64 36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, None, None, 64 0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, None, None, 12 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, None, None, 12 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, None, None, 25 295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, None, None, 25 590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, None, None, 25 590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, None, None, 51 1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, None, None, 51 2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, None, None, 51 2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 51 0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, None, None, 51 2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, None, None, 51 2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, None, None, 51 2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, None, None, 51 0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load very small set of cats and dogs data (from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = 'data/dogs_and_cats/train'\n",
    "val_data_dir = 'data/dogs_and_cats/val'\n",
    "n_cats_training = 40\n",
    "n_dogs_training = 40\n",
    "training_size = n_cats_training + n_dogs_training\n",
    "\n",
    "n_cats_val = 10\n",
    "n_dogs_val = 10\n",
    "val_size = n_cats_val + n_dogs_val\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform or \"featurize\" data with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "                            train_data_dir,\n",
    "                            target_size=(150, 150),\n",
    "                            class_mode=None,\n",
    "                            shuffle=False) # keep data in order, since this is only a transform\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "                            val_data_dir,\n",
    "                            target_size=(150, 150),\n",
    "                            class_mode=None,\n",
    "                            shuffle=False)\n",
    "\n",
    "train_data = model.predict_generator(train_generator, training_size)\n",
    "val_data = model.predict_generator(val_generator, val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_labels = np.array([0] * n_cats_training + [1] * n_dogs_training)\n",
    "val_labels = np.array([0] * n_cats_val + [1] * n_dogs_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model baed on features of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 0s - loss: 1.4616 - acc: 0.5250 - val_loss: 0.6621 - val_acc: 0.6500\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s - loss: 0.4685 - acc: 0.7250 - val_loss: 0.8102 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s - loss: 0.1859 - acc: 0.9500 - val_loss: 0.2941 - val_acc: 0.9000\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s - loss: 0.1354 - acc: 0.9500 - val_loss: 0.2667 - val_acc: 0.9000\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s - loss: 0.0586 - acc: 0.9875 - val_loss: 0.6656 - val_acc: 0.8000\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s - loss: 0.0422 - acc: 1.0000 - val_loss: 0.8947 - val_acc: 0.7500\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s - loss: 0.0332 - acc: 1.0000 - val_loss: 0.7032 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4653 - val_acc: 0.8000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3496 - val_acc: 0.8500\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.3371 - val_acc: 0.8500\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4134 - val_acc: 0.8500\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5220 - val_acc: 0.8000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6060 - val_acc: 0.8000\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.8000\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6418 - val_acc: 0.8000\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4913 - val_acc: 0.8000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4517 - val_acc: 0.8500\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114d3c9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          nb_epoch=20,\n",
    "          validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
