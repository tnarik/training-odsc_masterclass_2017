{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.read_csv('data/hourly_wages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.024064</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>13.018727</td>\n",
       "      <td>17.822097</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.139097</td>\n",
       "      <td>0.384360</td>\n",
       "      <td>2.615373</td>\n",
       "      <td>12.379710</td>\n",
       "      <td>11.726573</td>\n",
       "      <td>0.498767</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\n",
       "count     534.000000  534.000000     534.000000      534.000000  534.000000   \n",
       "mean        9.024064    0.179775      13.018727       17.822097   36.833333   \n",
       "std         5.139097    0.384360       2.615373       12.379710   11.726573   \n",
       "min         1.000000    0.000000       2.000000        0.000000   18.000000   \n",
       "25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n",
       "50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n",
       "75%        11.250000    0.000000      15.000000       26.000000   44.000000   \n",
       "max        44.500000    1.000000      18.000000       55.000000   64.000000   \n",
       "\n",
       "           female        marr       south  manufacturing  construction  \n",
       "count  534.000000  534.000000  534.000000     534.000000    534.000000  \n",
       "mean     0.458801    0.655431    0.292135       0.185393      0.044944  \n",
       "std      0.498767    0.475673    0.455170       0.388981      0.207375  \n",
       "min      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n",
       "75%      1.000000    1.000000    1.000000       0.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data_df.wage_per_hour.as_matrix()\n",
    "predictors = data_df.drop(['wage_per_hour'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 100)           1000        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           10100       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             101         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 11,201\n",
      "Trainable params: 11,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "my_model.add(Dense(100, activation='relu'))\n",
    "my_model.add(Dense(1))\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "534/534 [==============================] - 0s - loss: 70.0865     \n",
      "Epoch 2/10\n",
      "534/534 [==============================] - 0s - loss: 26.9606     \n",
      "Epoch 3/10\n",
      "534/534 [==============================] - 0s - loss: 22.5278     \n",
      "Epoch 4/10\n",
      "534/534 [==============================] - 0s - loss: 21.6223     \n",
      "Epoch 5/10\n",
      "534/534 [==============================] - 0s - loss: 21.7286     \n",
      "Epoch 6/10\n",
      "534/534 [==============================] - 0s - loss: 22.1453     \n",
      "Epoch 7/10\n",
      "534/534 [==============================] - 0s - loss: 21.0051     \n",
      "Epoch 8/10\n",
      "534/534 [==============================] - 0s - loss: 21.1930     \n",
      "Epoch 9/10\n",
      "534/534 [==============================] - 0s - loss: 21.3519     \n",
      "Epoch 10/10\n",
      "534/534 [==============================] - 0s - loss: 21.6887     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118170cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 161 samples\n",
      "Epoch 1/10\n",
      "373/373 [==============================] - 0s - loss: 49.8994 - val_loss: 34.6380\n",
      "Epoch 2/10\n",
      "373/373 [==============================] - 0s - loss: 28.0559 - val_loss: 30.1449\n",
      "Epoch 3/10\n",
      "373/373 [==============================] - 0s - loss: 22.5016 - val_loss: 28.7867\n",
      "Epoch 4/10\n",
      "373/373 [==============================] - 0s - loss: 20.4312 - val_loss: 24.9016\n",
      "Epoch 5/10\n",
      "373/373 [==============================] - 0s - loss: 19.7778 - val_loss: 25.6970\n",
      "Epoch 6/10\n",
      "373/373 [==============================] - 0s - loss: 19.5629 - val_loss: 25.0543\n",
      "Epoch 7/10\n",
      "373/373 [==============================] - 0s - loss: 19.8188 - val_loss: 25.2674\n",
      "Epoch 8/10\n",
      "373/373 [==============================] - 0s - loss: 19.4770 - val_loss: 25.2308\n",
      "Epoch 9/10\n",
      "373/373 [==============================] - 0s - loss: 19.4184 - val_loss: 25.6940\n",
      "Epoch 10/10\n",
      "373/373 [==============================] - 0s - loss: 19.3741 - val_loss: 25.4255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1189d2828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_new_model():\n",
    "    my_model = Sequential()\n",
    "    my_model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "    my_model.add(Dense(100, activation='relu'))\n",
    "    my_model.add(Dense(1))\n",
    "    my_model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    return(my_model)\n",
    "my_model = get_new_model()\n",
    "my_model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 373 samples, validate on 161 samples\n",
      "Epoch 1/20\n",
      "373/373 [==============================] - 0s - loss: 57.9855 - val_loss: 37.6224\n",
      "Epoch 2/20\n",
      "373/373 [==============================] - 0s - loss: 27.6005 - val_loss: 35.2617\n",
      "Epoch 3/20\n",
      "373/373 [==============================] - 0s - loss: 22.1495 - val_loss: 26.1218\n",
      "Epoch 4/20\n",
      "373/373 [==============================] - 0s - loss: 20.6510 - val_loss: 25.7686\n",
      "Epoch 5/20\n",
      "373/373 [==============================] - 0s - loss: 20.2414 - val_loss: 25.6822\n",
      "Epoch 6/20\n",
      "373/373 [==============================] - 0s - loss: 19.9175 - val_loss: 25.4558\n",
      "Epoch 7/20\n",
      "373/373 [==============================] - 0s - loss: 19.8169 - val_loss: 25.9288\n",
      "Epoch 8/20\n",
      "373/373 [==============================] - 0s - loss: 19.6836 - val_loss: 25.4549\n",
      "Epoch 9/20\n",
      "373/373 [==============================] - 0s - loss: 19.4733 - val_loss: 26.3522\n",
      "Epoch 10/20\n",
      "373/373 [==============================] - 0s - loss: 19.9091 - val_loss: 27.3344\n",
      "Epoch 11/20\n",
      "373/373 [==============================] - 0s - loss: 19.5699 - val_loss: 26.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118fdad68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "my_model = get_new_model()\n",
    "my_model.fit(predictors, target, validation_split=0.3, nb_epoch=20, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1           False   \n",
       "1         1       1  38.0      1      0  71.2833     0           False   \n",
       "2         1       3  26.0      0      0   7.9250     0           False   \n",
       "3         1       1  35.0      1      0  53.1000     0           False   \n",
       "4         0       3  35.0      0      0   8.0500     1           False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv('data/titanic_all_numeric.csv')\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/20\n",
      "623/623 [==============================] - 0s - loss: 0.7890 - acc: 0.6100 - val_loss: 0.7363 - val_acc: 0.6679\n",
      "Epoch 2/20\n",
      "623/623 [==============================] - 0s - loss: 0.6979 - acc: 0.6421 - val_loss: 0.5570 - val_acc: 0.7313\n",
      "Epoch 3/20\n",
      "623/623 [==============================] - 0s - loss: 0.6467 - acc: 0.6934 - val_loss: 0.5769 - val_acc: 0.6754\n",
      "Epoch 4/20\n",
      "623/623 [==============================] - 0s - loss: 0.6333 - acc: 0.6693 - val_loss: 0.5371 - val_acc: 0.7425\n",
      "Epoch 5/20\n",
      "623/623 [==============================] - 0s - loss: 0.5902 - acc: 0.6886 - val_loss: 0.4926 - val_acc: 0.7425\n",
      "Epoch 6/20\n",
      "623/623 [==============================] - 0s - loss: 0.5878 - acc: 0.6902 - val_loss: 0.5084 - val_acc: 0.7425\n",
      "Epoch 7/20\n",
      "623/623 [==============================] - 0s - loss: 0.5719 - acc: 0.7175 - val_loss: 0.4732 - val_acc: 0.7649\n",
      "Epoch 8/20\n",
      "623/623 [==============================] - 0s - loss: 0.5835 - acc: 0.7127 - val_loss: 0.5240 - val_acc: 0.7313\n",
      "Epoch 9/20\n",
      "623/623 [==============================] - 0s - loss: 0.5922 - acc: 0.7319 - val_loss: 0.4788 - val_acc: 0.7910\n",
      "Epoch 10/20\n",
      "623/623 [==============================] - 0s - loss: 0.5595 - acc: 0.7335 - val_loss: 0.5214 - val_acc: 0.7649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a025d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "target = to_categorical(titanic_data.survived)\n",
    "predictors = titanic_data.drop(['survived'], axis=1).as_matrix()\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "def get_classification_model(n_cols):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "my_model = get_classification_model(n_cols)\n",
    "my_model.fit(predictors, target, validation_split=0.3, nb_epoch=20, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks (Working with Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Using tf dim ordering\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 27, 27, 8)     40          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 26, 26, 8)     264         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 13, 13, 8)     0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1352)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 100)           135300      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 10)            1010        dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 136,614\n",
      "Trainable params: 136,614\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 8\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (2, 2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape, activation='relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_2 (Flatten)              (None, 8192)          0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 256)           2097408     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 1)             257         dense_16[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 78s - loss: 0.2321 - acc: 0.9319 - val_loss: 0.0895 - val_acc: 0.9724\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 79s - loss: 0.0782 - acc: 0.9759 - val_loss: 0.0652 - val_acc: 0.9784\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 79s - loss: 0.0529 - acc: 0.9834 - val_loss: 0.0489 - val_acc: 0.9827\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 78s - loss: 0.0394 - acc: 0.9876 - val_loss: 0.0517 - val_acc: 0.9840\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 78s - loss: 0.0309 - acc: 0.9903 - val_loss: 0.0513 - val_acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e78c940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (using Pre-Trained Networks)\n",
    "Loaded model from https://github.com/fchollet/deep-learning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "from vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, None, None, 64 1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, None, None, 64 36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, None, None, 64 0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, None, None, 12 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, None, None, 12 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, None, None, 25 295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, None, None, 25 590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, None, None, 25 590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, None, None, 51 1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, None, None, 51 2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, None, None, 51 2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 51 0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, None, None, 51 2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, None, None, 51 2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, None, None, 51 2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, None, None, 51 0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load very small set of cats and dogs data (from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = 'data/dogs_and_cats/train'\n",
    "val_data_dir = 'data/dogs_and_cats/val'\n",
    "n_cats_training = 40\n",
    "n_dogs_training = 40\n",
    "training_size = n_cats_training + n_dogs_training\n",
    "\n",
    "n_cats_val = 10\n",
    "n_dogs_val = 10\n",
    "val_size = n_cats_val + n_dogs_val\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform or \"featurize\" data with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "                            train_data_dir,\n",
    "                            target_size=(150, 150),\n",
    "                            class_mode=None,\n",
    "                            shuffle=False) # keep data in order, since this is only a transform\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "                            val_data_dir,\n",
    "                            target_size=(150, 150),\n",
    "                            class_mode=None,\n",
    "                            shuffle=False)\n",
    "\n",
    "train_data = model.predict_generator(train_generator, training_size)\n",
    "val_data = model.predict_generator(val_generator, val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_labels = np.array([0] * n_cats_training + [1] * n_dogs_training)\n",
    "val_labels = np.array([0] * n_cats_val + [1] * n_dogs_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model baed on features of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 0s - loss: 1.5143 - acc: 0.5000 - val_loss: 2.1882 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s - loss: 1.5431 - acc: 0.5875 - val_loss: 0.6620 - val_acc: 0.6500\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s - loss: 0.4394 - acc: 0.7250 - val_loss: 0.9542 - val_acc: 0.5500\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s - loss: 0.1767 - acc: 0.9750 - val_loss: 0.3241 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s - loss: 0.2968 - acc: 0.8375 - val_loss: 0.3047 - val_acc: 0.8500\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s - loss: 0.1238 - acc: 0.9375 - val_loss: 0.5958 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s - loss: 0.0940 - acc: 0.9625 - val_loss: 1.0830 - val_acc: 0.6500\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s - loss: 0.0920 - acc: 0.9625 - val_loss: 0.6519 - val_acc: 0.8000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s - loss: 0.0272 - acc: 1.0000 - val_loss: 0.3064 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s - loss: 0.0320 - acc: 1.0000 - val_loss: 0.2467 - val_acc: 0.9500\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s - loss: 0.0305 - acc: 1.0000 - val_loss: 0.2828 - val_acc: 0.9500\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4455 - val_acc: 0.8000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8000\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 0.8000\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.8000\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5759 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4932 - val_acc: 0.8000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4412 - val_acc: 0.8500\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4196 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ac99a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          nb_epoch=20,\n",
    "          validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
